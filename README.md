# Amazon ML Challenge 2025 - Multi-Modal Price Prediction

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A comprehensive multi-modal machine learning solution for predicting product prices using both text descriptions and product images. This system combines state-of-the-art language models (Mistral-7B) with vision transformers (CLIP) to achieve accurate price predictions for e-commerce products.

## ğŸš€ Key Features

- **Multi-Modal Architecture**: Combines text and image information for better predictions
- **State-of-the-Art Models**: Uses Mistral-7B for text encoding and CLIP ViT-Large for image processing
- **Advanced Optimization**: 4-bit quantization, LoRA fine-tuning, and mixed precision training
- **Robust Training Pipeline**: Cross-validation, early stopping, and comprehensive logging
- **Feature Engineering**: Advanced text and image feature extraction
- **Ensemble Predictions**: Multiple model checkpoints for improved accuracy
- **Post-Processing**: Smart price range adjustments and outlier handling

## ğŸ“ Project Structure

```
amazon-ml-2025/
â”œâ”€â”€ src/                          # Core source code
â”‚   â”œâ”€â”€ __init__.py              # Package initialization
â”‚   â”œâ”€â”€ config.py                # Configuration management
â”‚   â”œâ”€â”€ data.py                  # Data loading and image downloading
â”‚   â”œâ”€â”€ features.py              # Feature extraction utilities
â”‚   â”œâ”€â”€ loss.py                  # Custom loss functions (SMAPE, Combined)
â”‚   â”œâ”€â”€ models.py                # Neural network architectures
â”‚   â”œâ”€â”€ train.py                 # Training pipeline and cross-validation
â”‚   â”œâ”€â”€ infer.py                 # Inference and ensemble predictions
â”‚   â”œâ”€â”€ validate.py              # Model validation and analysis
â”‚   â””â”€â”€ utils.py                 # Utility functions
â”œâ”€â”€ scripts/                      # Utility scripts
â”‚   â”œâ”€â”€ download_images.py       # Image downloading script
â”‚   â”œâ”€â”€ train.sh                 # Training pipeline script
â”‚   â”œâ”€â”€ predict.sh               # Prediction script
â”‚   â””â”€â”€ validate.sh              # Validation script
â”œâ”€â”€ configs/                      # Configuration files
â”‚   â””â”€â”€ config.yaml              # Main configuration file
â”œâ”€â”€ dataset/                      # Data directory
â”‚   â”œâ”€â”€ train.csv                # Training data (place here)
â”‚   â”œâ”€â”€ test.csv                 # Test data (place here)
â”‚   â”œâ”€â”€ sample_test.csv          # Sample test data
â”‚   â”œâ”€â”€ images/                  # Downloaded images
â”‚   â””â”€â”€ features/                # Extracted features
â”œâ”€â”€ output/                       # Training outputs
â”‚   â”œâ”€â”€ checkpoints/             # Model checkpoints
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â””â”€â”€ validation/              # Validation results
â”œâ”€â”€ submissions/                  # Final predictions
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ setup.py                     # Package setup
â””â”€â”€ README.md                    # This file
```

## ğŸ› ï¸ Installation

### Option 1: Quick Install (Recommended)

```bash
# Clone the repository
git clone https://github.com/your-username/amazon-ml-2025.git
cd amazon-ml-2025

# Install the package
pip install -e .

# For GPU support and all features
pip install -e ".[all]"
```

### Option 2: Manual Setup

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install the package in development mode
pip install -e .
```

### System Requirements

- **Python**: 3.8 or higher
- **GPU**: NVIDIA GPU with 8GB+ VRAM (recommended)
- **RAM**: 16GB+ system RAM
- **Storage**: 50GB+ free space for models and data

## ğŸ“Š Data Setup

1. **Download Competition Data**:
   - Place `train.csv` and `test.csv` in the `dataset/` folder
   - Ensure CSV files contain required columns: `sample_id`, `product_title`, `image_link`, `price` (for train)

2. **Download Product Images**:
   ```bash
   # Using the provided script
   python scripts/download_images.py \
     --train-csv dataset/train.csv \
     --test-csv dataset/test.csv \
     --train-output dataset/images/train \
     --test-output dataset/images/test \
     --num-workers 8
   ```

   Or using the command-line tool:
   ```bash
   amazon-ml-download \
     --train-csv dataset/train.csv \
     --test-csv dataset/test.csv \
     --train-output dataset/images/train \
     --test-output dataset/images/test
   ```

## âš™ï¸ Configuration

Edit `configs/config.yaml` to customize the model and training parameters:

```yaml
# Key parameters to adjust
model:
  text_model: "mistralai/Mistral-7B-v0.1"
  image_model: "openai/clip-vit-large-patch14"
  fusion_hidden_dims: [2048, 1024, 512, 256]

training:
  batch_size: 8
  num_epochs: 10
  learning_rate: 2e-5
  num_folds: 5

system:
  num_workers: 4
  wandb_project: "amazon-ml-2025"
```

## ğŸ¯ Training

### Quick Start

```bash
# Using the training script
bash scripts/train.sh

# Or directly with Python
amazon-ml-train --config configs/config.yaml
```

### Advanced Training Options

```bash
# Custom configuration
bash scripts/train.sh --config custom_config.yaml --experiment-name my-experiment

# Resume from checkpoint
bash scripts/train.sh --resume output/checkpoints/fold0_best.pt

# With Weights & Biases logging
bash scripts/train.sh --wandb-project my-project
```

### Training Process

The training pipeline includes:

1. **Data Preprocessing**: Feature extraction and price normalization
2. **Cross-Validation**: 5-fold stratified cross-validation
3. **Multi-Modal Training**: Text + image encoders with fusion model
4. **Optimization**: Mixed precision, gradient accumulation, early stopping
5. **Checkpointing**: Best model per fold saved automatically

## ğŸ”® Inference

### Generate Predictions

```bash
# Using the prediction script
bash scripts/predict.sh

# Or directly
amazon-ml-predict --config configs/config.yaml
```

### Ensemble Predictions

The system automatically:
- Loads all fold checkpoints
- Generates ensemble predictions
- Applies post-processing for price range validation
- Saves final submission to `submissions/submission.csv`

### Prediction Pipeline

1. **Feature Extraction**: Same preprocessing as training
2. **Ensemble Inference**: Average predictions from all folds
3. **Post-Processing**: Price range validation and outlier smoothing
4. **Output**: Ready-to-submit CSV file

## ğŸ“ˆ Validation and Analysis

### Model Validation

```bash
# Comprehensive validation
bash scripts/validate.sh

# Or directly
amazon-ml-validate --config configs/config.yaml
```

### Validation Outputs

- **Metrics**: SMAPE, MAE, MSE, RÂ², correlation analysis
- **Visualizations**: Prediction plots, error distributions, residual analysis
- **Error Analysis**: Performance by category, price range, and product attributes
- **Cross-Validation Summary**: Stability and consistency metrics

## ğŸ§  Model Architecture

### Text Encoder
- **Base Model**: Mistral-7B-v0.1
- **Optimization**: 4-bit quantization + LoRA fine-tuning
- **Features**: Product title, description, specifications

### Image Encoder  
- **Base Model**: CLIP ViT-Large-patch14
- **Features**: Visual appearance, text-in-image, image quality metrics

### Fusion Model
- **Architecture**: Multi-layer perceptron with attention mechanism
- **Input**: Concatenated text + image embeddings + handcrafted features
- **Output**: Single price prediction

### Loss Function
- **Primary**: SMAPE (Symmetric Mean Absolute Percentage Error)
- **Secondary**: Combined SMAPE + MSE loss
- **Advanced**: Focal SMAPE for hard examples

## ğŸ“‹ Key Features

### Advanced Feature Engineering
- **Text Features**: IPQ extraction, brand detection, category classification
- **Image Features**: Dimensions, quality metrics, visual statistics
- **Price Features**: Log transformation, percentile clipping

### Training Optimizations
- **Memory Efficiency**: Gradient checkpointing, mixed precision
- **Stability**: Gradient clipping, weight decay, early stopping
- **Reproducibility**: Fixed seeds, deterministic operations

### Robust Predictions
- **Ensemble**: Multiple fold predictions
- **Post-Processing**: Price range validation, outlier smoothing
- **Quality Assurance**: Comprehensive validation metrics

## ğŸ”§ Development

### Code Quality

```bash
# Install development dependencies
pip install -e ".[development]"

# Format code
black src/ scripts/
isort src/ scripts/

# Lint code
flake8 src/ scripts/

# Run tests
pytest tests/
```

### Adding New Features

1. **Models**: Add new architectures in `src/models.py`
2. **Features**: Extend feature extraction in `src/features.py`
3. **Losses**: Implement custom losses in `src/loss.py`
4. **Configs**: Update `configs/config.yaml` for new parameters

## ğŸ“Š Performance

### Baseline Results
- **Cross-Validation SMAPE**: ~12-15%
- **Training Time**: ~2-4 hours per fold on RTX 4090
- **Inference Speed**: ~1000 samples/second

### Optimization Tips
- **Batch Size**: Increase for better GPU utilization
- **Mixed Precision**: Reduces memory usage by 40%
- **Gradient Accumulation**: Enables larger effective batch sizes
- **LoRA**: Reduces trainable parameters by 99%

## ğŸš¨ Troubleshooting

### Common Issues

1. **Out of Memory**:
   - Reduce `batch_size` in config
   - Enable `gradient_checkpointing`
   - Use smaller image models

2. **Slow Training**:
   - Increase `num_workers` for data loading
   - Use `mixed_precision: true`
   - Optimize `dataloader_pin_memory`

3. **Poor Performance**:
   - Increase `num_epochs`
   - Adjust `learning_rate`
   - Enable more feature engineering

4. **Missing Images**:
   - Check internet connection
   - Increase `max_retries` in download script
   - Verify CSV URLs are valid

### Debug Mode

```bash
# Enable detailed logging
export LOG_LEVEL=DEBUG

# Run with single worker for debugging
bash scripts/train.sh --config configs/debug_config.yaml
```

## ğŸ“š Resources

### Documentation
- [Model Architecture Details](docs/models.md)
- [Feature Engineering Guide](docs/features.md)
- [Training Best Practices](docs/training.md)
- [Deployment Guide](docs/deployment.md)

### References
- [Mistral 7B Paper](https://arxiv.org/abs/2310.06825)
- [CLIP Paper](https://arxiv.org/abs/2103.00020)
- [LoRA Paper](https://arxiv.org/abs/2106.09685)
- [QLoRA Paper](https://arxiv.org/abs/2305.14314)

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Development Workflow
1. Fork the repository
2. Create a feature branch
3. Make changes with tests
4. Submit a pull request

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Amazon ML Challenge organizers
- Hugging Face for model hosting
- PyTorch team for the framework
- Open source community for libraries

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/your-username/amazon-ml-2025/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-username/amazon-ml-2025/discussions)
- **Email**: your-email@example.com

---

**Happy Modeling! ğŸš€**

*Built with â¤ï¸ for the Amazon ML Challenge 2025*